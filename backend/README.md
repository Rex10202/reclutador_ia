# Backend API - COTECMAR Reclutador IA

Arquitectura modular y escalable para anÃ¡lisis y matching de hojas de vida.

## ğŸ“ Estructura del Proyecto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI application factory
â”‚   â”œâ”€â”€ config.py                  # Configuration management
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ exceptions.py          # Custom exceptions
â”‚   â”‚   â”œâ”€â”€ logger.py              # Logging setup
â”‚   â”‚   â””â”€â”€ security.py            # File validation & security
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ documents/         # Module 1: CV Analysis
â”‚   â”‚       â”‚   â””â”€â”€ router.py      # POST /api/v1/documents/upload
â”‚   â”‚       â””â”€â”€ search/            # Module 2: NL Search (fallback)
â”‚   â”‚           â””â”€â”€ router.py      # POST /api/v1/search
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py       # PDF/DOCX text extraction
â”‚   â”‚   â”œâ”€â”€ cv_extractor.py        # Attribute extraction (NLP integration)
â”‚   â”‚   â””â”€â”€ matching_engine.py     # Scoring & ranking
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py             # Pydantic schemas (DTOs)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_handler.py        # File management utilities
â”‚       â””â”€â”€ validators.py          # Input validation
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ run.py                         # Entry point
```

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### 1. Crear virtualenv (si no existe)
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
# o: source venv/bin/activate  # Linux/Mac
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Ejecutar servidor
```bash
python run.py
```

El servidor estarÃ¡ disponible en:
- **API**: http://127.0.0.1:8000
- **Swagger Docs**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

## ğŸ“š API Endpoints

### Module 1: CV Analysis (MÃ³dulo Principal)

#### `POST /api/v1/documents/upload`
Subir y analizar mÃºltiples CVs.

**Request:**
```bash
curl -X POST "http://127.0.0.1:8000/api/v1/documents/upload" \
  -H "accept: application/json" \
  -F "files=@resume1.pdf" \
  -F "files=@resume2.pdf"
```

**Response:**
```json
[
  {
    "document_id": "uuid-here",
    "filename": "resume1.pdf",
    "status": "success",
    "extracted_attributes": [
      {
        "attribute_type": "role",
        "value": "Software Engineer",
        "confidence": 0.95,
        "source_text": "Software Engineer with 5 years..."
      }
    ],
    "raw_text_preview": "John Doe\nSoftware Engineer\n...",
    "processing_time_ms": 245.3
  }
]
```

**Validaciones:**
- MÃ­nimo 2 archivos, mÃ¡ximo 10
- Formatos soportados: PDF, DOCX, DOC, TXT
- TamaÃ±o mÃ¡ximo: 50MB por archivo

---

#### `GET /api/v1/documents/{document_id}`
Recuperar anÃ¡lisis previo de un documento.

**Response:**
```json
{
  "document_id": "uuid-here",
  "filename": "resume1.pdf",
  "status": "success",
  "extracted_attributes": [...],
  "raw_text_preview": "..."
}
```

---

#### `DELETE /api/v1/documents/{document_id}`
Eliminar un documento y su anÃ¡lisis.

**Response:** `204 No Content`

---

### Module 2: Natural Language Search (Fallback)

#### `POST /api/v1/search`
BÃºsqueda por lenguaje natural (cuando no se encuentren perfiles en CVs).

**Request:**
```json
{
  "text": "Ingeniero de software con 5 aÃ±os en Python y React, ubicado en BogotÃ¡"
}
```

**Response:**
```json
{
  "candidates": [
    {
      "id": "123",
      "role": "Software Engineer",
      "score": 0.92,
      "location": "BogotÃ¡",
      "years_experience": 5,
      "languages": "Spanish;English",
      "skills": "Python;React;PostgreSQL"
    }
  ],
  "parsed_query": {
    "role": "Software Engineer",
    "skills": ["Python", "React"],
    "experience_years": 5,
    "location": "BogotÃ¡",
    "languages": ["Spanish", "English"]
  },
  "total_results": 15
}
```

---

### Health Checks

#### `GET /health`
Estado general del servicio.

**Response:**
```json
{
  "status": "ok",
  "service": "reclutador_ia_backend"
}
```

---

#### `GET /health/ready`
VerificaciÃ³n de preparaciÃ³n para recibir requests.

**Response:**
```json
{
  "ready": true,
  "timestamp": "2025-12-11T10:30:45.123Z"
}
```

---

## ğŸ”§ ConfiguraciÃ³n

Todas las variables de configuraciÃ³n estÃ¡n en `backend/.env`:

```env
# API
HOST=127.0.0.1
PORT=8000
DEBUG=True
RELOAD=True

# CORS (Frontend)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://localhost:8000

# File Upload
MAX_FILE_SIZE_MB=50
MAX_UPLOAD_FILES=10
UPLOAD_TEMP_DIR=/tmp/uploads

# NLP & Models
MODELS_PATH=./models
NLP_PARSER_MODEL=beto
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# Logging
LOG_LEVEL=INFO
```

## ğŸ—ï¸ Arquitectura de Capas

### 1. **API Layer** (`api/v1/`)
- Rutas HTTP
- ValidaciÃ³n de requests (Pydantic)
- Manejo de errores
- DocumentaciÃ³n automÃ¡tica (Swagger)

### 2. **Service Layer** (`services/`)
- `PDFProcessor`: ExtracciÃ³n de texto de documentos
- `CVExtractor`: AnÃ¡lisis NLP de atributos
- `MatchingEngine`: Scoring y ranking

### 3. **Core Layer** (`core/`)
- `exceptions.py`: Excepciones personalizadas
- `logger.py`: Sistema de logging centralizado
- `security.py`: Validaciones de archivos

### 4. **Models Layer** (`models/`)
- Pydantic schemas (DTOs)
- ValidaciÃ³n de datos centralizada
- DocumentaciÃ³n automÃ¡tica de tipos

### 5. **Utils Layer** (`utils/`)
- Funciones utilitarias
- Validadores personalizados
- Manejo de archivos

## âœ¨ CaracterÃ­sticas

âœ… **Modularidad**: FÃ¡cil de escalar y mantener
âœ… **Type Hints**: Python 3.9+ con tipos completos
âœ… **ValidaciÃ³n**: Pydantic + custom validators
âœ… **DocumentaciÃ³n**: Swagger automÃ¡tico + docstrings
âœ… **Error Handling**: Excepciones consistentes
âœ… **Logging**: Sistema centralizado
âœ… **CORS**: ConfiguraciÃ³n flexible para frontend
âœ… **Async**: Operaciones asincrÃ³nicas para mejor performance

## ğŸ”Œ IntegraciÃ³n con MÃ³dulos Existentes

### NLP Module
El `CVExtractor` integrarÃ¡ con `NLP/src/parser.py` para:
- DetecciÃ³n de roles (BETO embeddings)
- ExtracciÃ³n de skills
- CÃ¡lculo de aÃ±os de experiencia
- DetecciÃ³n de ubicaciÃ³n e idiomas

### Ranking Model
El `MatchingEngine` integrarÃ¡ con `ranking_model/` para:
- CÃ¡lculo de embeddings semÃ¡nticos
- Scoring de candidatos
- AplicaciÃ³n de filtros (lexical + semantic)

## ğŸ“ PrÃ³ximos Pasos

- [ ] IntegraciÃ³n completa con NLP module
- [ ] IntegraciÃ³n con ranking_model
- [ ] Implementar persistencia de documentos (DB)
- [ ] CachÃ© de embeddings
- [ ] Tests unitarios y E2E
- [ ] Docker containerization
- [ ] CI/CD pipeline

## ğŸ“§ Contacto

Equipo COTECMAR
