# Backend API - COTECMAR Reclutador IA

API FastAPI para subir CVs, extraer atributos y comparar contra un perfil de puesto.

El extractor real vive en `packages/cv-extraction` y el backend lo carga autom√°ticamente (v√≠a `sys.path`).

## üìÅ Estructura (relevante)

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Crea FastAPI + agrega rutas /api/*
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # APIRouter(prefix="/api")
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents/router.py    # /api/documents/* (flujo principal)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search/router.py       # /api/search/* (stub)
‚îÇ   ‚îú‚îÄ‚îÄ services/                  # wrappers hacia packages/cv-extraction
‚îÇ   ‚îî‚îÄ‚îÄ models/schemas.py          # esquemas
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ run.py                         # entrypoint uvicorn

packages/
‚îî‚îÄ‚îÄ cv-extraction/cv_extraction/   # extracci√≥n real (PDFProcessor + CVExtractor)
```

## üöÄ Instalaci√≥n y ejecuci√≥n (sin Docker)

Recomendado: crear el virtualenv en la ra√≠z del repo (para backend + packages).

### 1) Crear y activar entorno (Windows)
```bash
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 2) Instalar dependencias
```bash
pip install -r backend/requirements.txt
```

### 3) Instalar modelo de spaCy (recomendado)
El extractor usa `es_core_news_md` para mejorar detecci√≥n de rol/ubicaci√≥n.
```bash
python -m spacy download es_core_news_md
```

### 4) Ejecutar el backend
```bash
python backend/run.py
```

El servidor estar√° disponible en:
- **API**: http://127.0.0.1:8000
- **Swagger Docs**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc

Primera ejecuci√≥n (NLP): `transformers` descargar√° el modelo BETO `dccuchile/bert-base-spanish-wwm-cased`.
Esto puede tardar y requiere internet. Se cachea en la carpeta de Hugging Face del usuario.

Windows: por defecto `UPLOAD_TEMP_DIR` es `/tmp/uploads` y normalmente termina como `C:\\tmp\\uploads`.
Si prefieres que quede dentro del repo, define `UPLOAD_TEMP_DIR=./tmp/uploads` en `backend/.env`.

## üìö API Endpoints

### Module 1: CV Analysis (M√≥dulo Principal)

#### `POST /api/documents/upload`
Subir y analizar m√∫ltiples CVs.

**Request:**
```bash
curl -X POST "http://127.0.0.1:8000/api/documents/upload" \
  -H "accept: application/json" \
  -F "files=@resume1.pdf" \
  -F "files=@resume2.pdf"
```

**Response:**
```json
[
  {
    "document_id": "uuid-here",
    "filename": "resume1.pdf",
    "status": "success",
    "extracted_attributes": [
      {
        "attribute_type": "role",
        "value": "Software Engineer",
        "confidence": 0.95,
        "source_text": "Software Engineer with 5 years..."
      }
    ],
    "raw_text_preview": "John Doe\nSoftware Engineer\n...",
    "processing_time_ms": 245.3
  }
]
```

**Validaciones:**
- M√≠nimo 2 archivos, m√°ximo 10
- Formatos soportados: PDF, DOCX, DOC, TXT
- Tama√±o m√°ximo: 50MB por archivo

---

#### `GET /api/documents/{document_id}`
Recuperar an√°lisis previo de un documento.

**Response:**
```json
{
  "document_id": "uuid-here",
  "filename": "resume1.pdf",
  "status": "success",
  "extracted_attributes": [...],
  "raw_text_preview": "..."
}
```

---

#### `DELETE /api/documents/{document_id}`
Eliminar un documento y su an√°lisis.

**Response:** `204 No Content`

---

#### `GET /api/documents/{document_id}/file`
Devuelve el archivo original (PDF) para visualizarlo (iframe / nueva pesta√±a).

### Search (placeholder)

#### `POST /api/search`
Actualmente es un stub (no usado por el frontend).

**Request:**
```json
{
  "text": "Ingeniero de software con 5 a√±os en Python y React, ubicado en Bogot√°"
}
```

**Response:**
```json
{
  "candidates": [
    {
      "id": "123",
      "role": "Software Engineer",
      "score": 0.92,
      "location": "Bogot√°",
      "years_experience": 5,
      "languages": "Spanish;English",
      "skills": "Python;React;PostgreSQL"
    }
  ],
  "parsed_query": {
    "role": "Software Engineer",
    "skills": ["Python", "React"],
    "experience_years": 5,
    "location": "Bogot√°",
    "languages": ["Spanish", "English"]
  },
  "total_results": 15
}
```

---

### Health Checks

#### `GET /health`
Estado general del servicio.

**Response:**
```json
{
  "status": "ok",
  "service": "reclutador_ia_backend"
}
```

---

#### `GET /health/ready`
Verificaci√≥n de preparaci√≥n para recibir requests.

**Response:**
```json
{
  "ready": true,
  "timestamp": "2025-12-11T10:30:45.123Z"
}
```

---

## üîß Configuraci√≥n

Todas las variables de configuraci√≥n est√°n en `backend/.env`:

```env
# API
HOST=127.0.0.1
PORT=8000
DEBUG=True
RELOAD=True

# CORS (Frontend)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://localhost:8000

# File Upload
MAX_FILE_SIZE_MB=50
MAX_UPLOAD_FILES=10
UPLOAD_TEMP_DIR=/tmp/uploads

# NLP & Models
MODELS_PATH=./models
NLP_PARSER_MODEL=beto
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# Logging
LOG_LEVEL=INFO
```

## üèóÔ∏è Arquitectura de Capas

### 1. **API Layer** (`api/`)
- Rutas HTTP
- Validaci√≥n de requests (Pydantic)
- Manejo de errores
- Documentaci√≥n autom√°tica (Swagger)

### 2. **Service Layer** (`services/`)
- `PDFProcessor`: Extracci√≥n de texto de documentos
- `CVExtractor`: An√°lisis NLP de atributos
- `MatchingEngine`: Scoring y ranking

### 3. **Core Layer** (`core/`)
- `exceptions.py`: Excepciones personalizadas
- `logger.py`: Sistema de logging centralizado
- `security.py`: Validaciones de archivos

### 4. **Models Layer** (`models/`)
- Pydantic schemas (DTOs)
- Validaci√≥n de datos centralizada
- Documentaci√≥n autom√°tica de tipos

### 5. **Utils Layer** (`utils/`)
- Funciones utilitarias
- Validadores personalizados
- Manejo de archivos

## ‚ú® Caracter√≠sticas

‚úÖ **Modularidad**: F√°cil de escalar y mantener
‚úÖ **Type Hints**: Python 3.9+ con tipos completos
‚úÖ **Validaci√≥n**: Pydantic + custom validators
‚úÖ **Documentaci√≥n**: Swagger autom√°tico + docstrings
‚úÖ **Error Handling**: Excepciones consistentes
‚úÖ **Logging**: Sistema centralizado
‚úÖ **CORS**: Configuraci√≥n flexible para frontend
‚úÖ **Async**: Operaciones asincr√≥nicas para mejor performance

## üîå Integraci√≥n con M√≥dulos Existentes

### NLP Module
El `CVExtractor` integrar√° con `NLP/src/parser.py` para:
- Detecci√≥n de roles (BETO embeddings)
- Extracci√≥n de skills
- C√°lculo de a√±os de experiencia
- Detecci√≥n de ubicaci√≥n e idiomas

### Ranking Model
El `MatchingEngine` integrar√° con `ranking_model/` para:
- C√°lculo de embeddings sem√°nticos
- Scoring de candidatos
- Aplicaci√≥n de filtros (lexical + semantic)

## üìù Pr√≥ximos Pasos

- [ ] Integraci√≥n completa con NLP module
- [ ] Integraci√≥n con ranking_model
- [ ] Implementar persistencia de documentos (DB)
- [ ] Cach√© de embeddings
- [ ] Tests unitarios y E2E
- [ ] Docker containerization
- [ ] CI/CD pipeline

## üìß Contacto

Equipo COTECMAR
